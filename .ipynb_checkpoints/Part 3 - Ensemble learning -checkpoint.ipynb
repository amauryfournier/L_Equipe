{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Challenge Kaggle : Partie 3\n",
    "### Schwartz Antoine <br> Fournier Amaury"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous disposons de différents modèles apppris et sérialisés, cette dernière partie constite à les assembler afin de tirer parti de chacuns et d'augmenter les performances prédictives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#path = \"/media/3000708/ESD-USB/Kaggle/\"\n",
    "path = \"/Vrac/LMOR/\"\n",
    "#path = \"C:/Users/S4rge09/Documents/Python Scripts/\"\n",
    "#path  = \"C:/Users/afournier/Desktop/kaggle/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On recharge uniquement les dataframe de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dftest with features\n",
    "dftest = pd.read_csv(path + \"dftest.csv\")\n",
    "\n",
    "# dftrain_test with features\n",
    "dftrain_test = pd.read_csv(path + \"dftrain.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On les gère de la même manière que pour l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ---- Gérer les NaN\n",
    "\n",
    "# - Pour Test et Train_Test\n",
    "#dftest = dftest.fillna(dftest.mean())\n",
    "#dftrain_test = dftrain_test.fillna(dftrain_test.mean())\n",
    "dftest = dftest.fillna(-9999)\n",
    "dftrain_test = dftrain_test.fillna(-9999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sélection et chargement des modèles \n",
    "\n",
    "Ici nous chargeons uniquement les meilleurs modèles : \n",
    "\n",
    "- Extremmely Random Trees (400 estimateurs, maxdepth = 20, appris sur l'ensemble des features générés) \n",
    "- Gradient Boosting (1000 estimateurs, maxdepth = 7, learninrate=0.01, appris sur l'ensemble des features)\n",
    "- Random forest (100 estimateurs, maxdepth=20, appris sur les 20 meilleurs features pour ce modèle sélectionnées manuellement)\n",
    "- Modèle de Marshall Palmer créé en Partie 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "dfsample = pd.read_csv(path + \"sample_solution.csv\")\n",
    "dfmtrain = pd.read_csv(path + \"marshall_palmer_train.csv\")\n",
    "marshalltest = dfsample[\"Expected\"].as_matrix()\n",
    "marshall = dfmtrain[\"Expected\"].as_matrix()\n",
    "\n",
    "model_ET = pickle.load(open(path + \"ExtraTreesExp30FillNAfulltrain.pkl\", \"rb\"))\n",
    "model_GB = pickle.load(open(path + \"GboostExp30FillNAfulltrain.pkl\", \"rb\"))\n",
    "model_RF = pickle.load(open(path + \"RFExp30FillNAfulltraintop20.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtest = dftrain_test.copy()\n",
    "Xtest.drop(\"Expected\", axis=1, inplace=True)\n",
    "y_true = dftrain_test[\"Expected\"].as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  top 20 features du random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "listeTopRF = ['Ref_5x5_90th', 'radardist_km',  'RefComposite_5x5_10th',\n",
    "              'Zdr_5x5_50th','minutes_past','Zdr_5x5_90th','Ref_5x5_10th',\n",
    "              'Ref_5x5_50th', 'Max_Ref_5x5_50th','Max_radardist_km',\n",
    "              'Max_Ref_5x5_90th','Max_Ref_5x5_10th', 'Min_radardist_km', \n",
    "              'Std_minutes_past', 'Std_RhoHV_5x5_50th', 'Std_RhoHV_5x5_90th',\n",
    "              'Std_Zdr_5x5_50th']\n",
    "XtestRF = Xtest[listeTopRF]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### performances de chacun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:    2.9s\n",
      "[Parallel(n_jobs=8)]: Done 100 out of 100 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF\n",
      "131.633598907\n",
      "GB\n",
      "131.738229935\n",
      "ET\n",
      "131.460905078\n"
     ]
    }
   ],
   "source": [
    "y_pred_RF = model_RF.predict(XtestRF)\n",
    "y_pred_GB = model_GB.predict(Xtest)\n",
    "y_pred_ET = model_ET.predict(Xtest)\n",
    "#ypred_old_ET = model_ET.predict(Xtest)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "print \"RF\"\n",
    "print mean_absolute_error(y_true, y_pred_RF)\n",
    "print \"GB\"\n",
    "print mean_absolute_error(y_true, y_pred_GB)\n",
    "print \"ET\"\n",
    "print mean_absolute_error(y_true, y_pred_ET)\n",
    "\n",
    "# train_test = alldata\n",
    "#131.592336721 alldata exp > 9.5 top 20 sum miss max, dropNa + fillmean, no log1p   # ---> RF\n",
    "#131.559235647 alldata exp > 9.5 allfeatures, dropNa + fillmean, no log1p # ---> ExtraTrees\n",
    "\n",
    "# Expected final  < 30 :\n",
    "# ExtraTrees : 131.460905078\n",
    "# Gboost : 131.738229935\n",
    "# Random Forest (top 17) : 131.633598907"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate que l'ET est légerement plus performant mais on espère que les deux autres puisse apporter aussi de l'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Ensembling de nos modèles \n",
    "\n",
    "Notre ensembling se base sur une méthode naive qui consiste à pondérer les prédictions de chaque modèle pour optimiser le score final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quadruplet (0.0, 0.0, 0.8, 0.2)\n",
      "score 131.425355989\n"
     ]
    }
   ],
   "source": [
    "max_score = 100000\n",
    "quadruplet = (0,0,0,0)\n",
    "\n",
    "for a in range(11) :\n",
    "    for b in range(11) :\n",
    "        for c in range(11) :\n",
    "            for d in range(11) :\n",
    "                if a+b+c+d == 10 :\n",
    "                    alpha = (a*1.0)/10\n",
    "                    beta = (b*1.0)/10\n",
    "                    gamma = (c*1.0)/10\n",
    "                    delta = (d*1.0)/10 \n",
    "                    y_npred = (alpha*y_pred_RF + beta*y_pred_GB + gamma*y_pred_ET + delta*marshall)\n",
    "                    #y_npred = (alpha*y_pred_RF + beta*y_pred_GB)\n",
    "\n",
    "                    score = mean_absolute_error(y_true, y_npred)\n",
    "                    #print quadruplet\n",
    "\n",
    "                    if score < max_score :\n",
    "                        max_score = score\n",
    "                        quadruplet = (alpha,beta,gamma,delta)\n",
    "\n",
    "print \"quadruplet\", quadruplet\n",
    "print \"score\", max_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Malheureusement il s'avère que nos trois modèles ensemblistes apprennent de façon trop similaire, c'est pourquoi le gridsearch attribut le poids maximal au meilleur modèle et ignore les autres. Toutefois marshall palmer semble apporter de l'information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Affinage de la pondération entre ET et Marshall Palmer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0.00000000e+00   1.00000000e-03   2.00000000e-03 ...,   1.09700000e+00\n",
      "   1.09800000e+00   1.09900000e+00]\n",
      "[  1.09900000e+00   1.09800000e+00   1.09700000e+00 ...,   2.00000000e-03\n",
      "   1.00000000e-03   0.00000000e+00]\n",
      "couple (0.88500000000000001, 0.214)\n",
      "score 131.386896328\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\"alpha\" : np.arange(0,1.1,0.001), \"beta\" : np.arange(0,1.1,0.001)[::-1] }\n",
    "max_score = 100000\n",
    "couple = (0,0)\n",
    "\n",
    "print param_grid['alpha']\n",
    "print param_grid['beta']\n",
    "for a,b in zip(param_grid['alpha'], param_grid['beta']) :\n",
    "    y_npred = a*y_pred_ET + b*marshall\n",
    "    score = mean_absolute_error(y_true, y_npred)\n",
    "    #print a , b\n",
    "    #print score \n",
    "    #print \"\\n\"\n",
    "    if score < max_score :\n",
    "        max_score = score\n",
    "        couple = (a,b)\n",
    "print \"couple\", couple\n",
    "print \"score\", max_score\n",
    "\n",
    "\n",
    "# 131.564575603 alldata exp > 9.5 top 20 sum miss max, dropNa + fillmean, no log1p   # ---> RF\n",
    "# 131.529703353 alldata exp > 9.5 allfeatures, dropNa + fillmean, no log1p           # ---> ExtraTrees\n",
    "# avec couple 0.77600000000000002, 0.32300000000000001\n",
    "\n",
    "# --- RF \n",
    "#couple (0.81600000000000006, 0.18300000000000003)\n",
    "#score 131.533407723\n",
    "\n",
    "# -- GB \n",
    "#couple (0.72399999999999998, 0.275)\n",
    "#score 131.625438493\n",
    "\n",
    "# -- ET\n",
    "#couple (0.88500000000000001, 0.114)\n",
    "#score 131.386896328"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction final du test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- Prediction de notre model --\n",
    "pred = model_ET.predict(dftest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -- final pred\n",
    "pred_f = couple[0]*pred + couple[1]*marshalltest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dftest.index -= 1\n",
    "result = np.c_[dftest.index, pred_f]\n",
    "submit = pd.DataFrame(result, columns=['Id', 'Expected'])\n",
    "submit.Id = submit.Id.astype(int)\n",
    "submit.to_csv(path + \"Submit.csv\" , index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
